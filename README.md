# ğŸ¤– Self-RAG Agentic Workflow Evaluator

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-Framework-green.svg)](https://www.langchain.com/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Workflow-orange.svg)](https://www.langchain.com/langgraph)
[![License](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE)

A **Retrieval-Augmented Generation (RAG)** framework with self-reflection capabilities, powered by **LangChain**, **LangGraph**, and **Groq**. It evaluates document relevance, detects hallucinations, and assesses answer quality to build smarter, reliable RAG systems.

## âœ¨ Features

- ğŸ“š **Semantic Document Retrieval**: Uses FAISS for efficient vector search.
- ğŸ¯ **Relevance Grading**: LLM-powered scoring of retrieved documents.
- ğŸš¨ **Hallucination Detection**: Verifies response factuality against documents.
- âœ… **Answer Quality Assessment**: Ensures responses are accurate and relevant.
- ğŸ”„ **Agentic Workflow**: State-driven orchestration with LangGraph.
- ğŸ’¬ **Interactive CLI**: Test the system via a command-line chat interface.

## ğŸ—ï¸ Architecture

The system follows a multi-step workflow:

1. ğŸ“‚ **Vector Store Creation**: Processes PDFs and builds a FAISS index.
2. ğŸ” **Document Retrieval**: Retrieves documents based on semantic similarity.
3. ğŸ¯ **Relevance Grading**: Evaluates document usefulness for the query.
4. âœï¸ **Answer Generation**: Creates context-aware responses.
5. ğŸš¨ **Hallucination Checking**: Validates response accuracy.
6. âœ… **Answer Grading**: Assesses response quality and relevance.

## ğŸ“‚ Project Structure

```
self-rag-agentic-workflow-evaluator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ build_index.py         # Builds FAISS vector store
â”‚   â”œâ”€â”€ helper.py              # Core RAG functions
â”‚   â”œâ”€â”€ state.py               # Workflow state and grading models
â”‚   â””â”€â”€ workflow.py            # LangGraph workflow definition
â”œâ”€â”€ prompt/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ state_prompt.py        # Prompt templates
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ attention-is-all-you-need-Paper.pdf  # Sample document
â”œâ”€â”€ local_chat.py              # CLI-based chat interface
â”œâ”€â”€ notebook.ipynb             # Jupyter notebook for experimentation
â””â”€â”€ README.md
```

## âš¡ Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/ldotmithu/self-rag-agentic-workflow-evaluator.git
   cd self-rag-agentic-workflow-evaluator
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set Up Environment Variables**:
   Create a `.env` file in the root directory:
   ```bash
   GROQ_API_KEY=your_groq_api_key_here
   ```

## ğŸš€ Usage

1. **Build the Vector Store**:
   ```bash
   python src/build_index.py
   ```

2. **Run the Interactive Chat**:
   ```bash
   python local_chat.py
   ```

3. **Use in Python Code**:
   ```python
   from src.workflow import BuildGraph

   workflow = BuildGraph()
   graph = workflow.build_graph()
   response = graph.invoke({"question": "What is Machine Learning?"})
   print(response)
   ```

## ğŸ§© Key Components

### ğŸ“Œ State Management (`src/state.py`)
- **AgentState**: Manages workflow state.
- **GradeDocuments**: Scores document relevance.
- **GradeHallucinations**: Detects factual inaccuracies.
- **GradeAnswer**: Validates answer quality.

### ğŸ“Œ Core Functions (`src/helper.py`)
- `create_model()`: Initializes the ChatGroq model.
- `build_vector_store()`: Creates the FAISS index.
- `get_relevant_documents()`: Retrieves relevant documents.
- `grade_document()`: Scores document relevance.
- `generate_answer()`: Produces context-aware responses.
- `check_hallucination()`: Identifies factual errors.
- `grade_answer()`: Evaluates response quality.

### ğŸ“Œ Workflow (`src/workflow.py`)
- **BuildGraph**: Constructs the LangGraph workflow with conditional routing.
- Supports graph visualization.

## âš™ï¸ Configuration

- **Environment Variables**:
  - `GROQ_API_KEY`: API key for Groq LLM services.
- **Vector Store**:
  - Location: `faiss_index/`
  - Embeddings: HuggingFace Embeddings
  - Source: `Data/Final_Research_24474.pdf`

## ğŸ§ª Development & Testing

```bash
# Test vector store creation
python src/build_index.py

# Test workflow compilation
python -c "from src.workflow import BuildGraph; g = BuildGraph().build_graph(); print('âœ… Graph compiled')"

# Test chat interface
python local_chat.py
```

## ğŸ¤ Contributing

1. ğŸ´ Fork the repository.
2. ğŸŒ± Create a feature branch (`git checkout -b feature/YourFeature`).
3. ğŸ› ï¸ Add improvements with clear comments.
4. âœ… Test thoroughly.
5. ğŸ”„ Submit a pull request.

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- [LangChain](https://www.langchain.com/) & [LangGraph](https://www.langchain.com/langgraph)
- [Groq](https://groq.com/) for LLM services
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [HuggingFace](https://huggingface.co/) for embeddings